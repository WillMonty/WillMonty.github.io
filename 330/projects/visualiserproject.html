<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<title>Will & Sanketh Visualizer</title>
		<style>
			body 
			{
				background: #eeeeee;
				font-family: tahoma, verdana, sans serif;
			}

			canvas 
			{
				display: block;
				margin-left: auto;
				margin-right: auto;
				box-shadow: 4px 4px 8px rgba(0,0,0,0.5);
				background: black;
			}

			#trackControls, #audioEffects
			{
				margin-left: auto;
				margin-right: auto;
				margin-top: 2em;
				text-align: center;
			}

			#trackControls > *
			{
				margin-right: 1em;
			}

			#vid
			{
				visibility: hidden;
			}

			p
			{
				text-align: center;
			}
		</style>
		<script type="text/javascript" src="dat.gui.js"></script>
		<script>
			// An IIFE ("Iffy")
			(function(){
				"use strict";

				let NUM_SAMPLES = 512;
				let audioCtx, analyserNode, convolverNode, sourceNode;
				let canvas, ctx;
				let audioElement;
				let videoElement, videoSourceElement;
				let defaultSong = 'media/audio/New Adventure Theme.mp3';

				let bassPercent = 0;

				//Dat gui controls object
				let controlFunc = function()
				{
					this.invert = false;
					this.videosource = 'media/ninja.mp4';
					this.reverb = false;
				}
				let controls = new controlFunc();

				function init(){

					// set up canvas stuff
					canvas = document.querySelector('canvas');
					ctx = canvas.getContext("2d");
					videoElement = document.getElementById('vid');
					videoSourceElement = document.getElementById('vidsource');

					// get reference to <audio> element on page
					audioElement = document.querySelector('audio');

					// call our helper function and get an analyser node
					analyserNode = createWebAudioContextAndNodes(audioElement);

					// get sound track <select> and Full Screen button working
					setupUI();

					// load and play default sound into audio element
					playStream(audioElement,defaultSong);

					// start animation loop
					update();
				}


				function createWebAudioContextAndNodes(audioElement) {
					// create new AudioContext
					audioCtx = new (window.AudioContext || window.webkitAudioContext);

					// create an analyser node
					analyserNode = audioCtx.createAnalyser();

					//create convolver node
					convolverNode = audioCtx.createConvolver();

					// fft stands for Fast Fourier Transform
					analyserNode.fftSize = NUM_SAMPLES;


					// grab reverb impulse via XHR for convolver node
					let soundSource;
					let ajaxRequest = new XMLHttpRequest();
					ajaxRequest.open('GET', 'media/impulse.ogg', true);
					ajaxRequest.responseType = 'arraybuffer'; 
					//Get file as an array to be decoded

					ajaxRequest.onload = function() {
						let audioData = ajaxRequest.response;
						audioCtx.decodeAudioData(audioData, function(buffer) {
							convolverNode.buffer = buffer;
						}, function(e){"Error with decoding audio data" + e.err});
					}

					ajaxRequest.send(); //Send request to be loaded with above function

					// this is where we hook up the <audio> element to the analyserNode
					sourceNode = audioCtx.createMediaElementSource(audioElement); 
					sourceNode.connect(analyserNode);

					// here we connect to the destination i.e. speakers
					analyserNode.connect(audioCtx.destination);
					return analyserNode;
				}

				function setupUI(){

					//Set up dat.GUI
					let gui = new dat.GUI();
					let reverbGUI = gui.add(controls, 'reverb');
					let invertGUI = gui.add(controls, 'invert');
					let videoGUI = gui.add(controls, 'videosource', {Ninja: 'media/ninja.mp4', Worm: 'media/worm.mp4',});

					reverbGUI.onChange(function(value) {
						if(value) //Reconnect nodes with convolver if reverb checked
						{
							sourceNode.connect(convolverNode);
							convolverNode.connect(analyserNode);
							analyserNode.connect(audioCtx.destination);
						}
						else
						{
							convolverNode.disconnect();			
						}
					});

					videoGUI.onChange(function(value) {
						videoSourceElement.setAttribute('src', value);
						videoElement.load();
						videoElement.play();
					});


					//Set up audio section
					document.querySelector("#trackSelect").onchange = function(e){
						playStream(audioElement,e.target.value);
					};

					document.querySelector("#fsButton").onclick = function(){
						requestFullscreen(canvas);
					};

				}

				function playStream(audioElement,path){
					audioElement.src = path;
					audioElement.play();
					audioElement.volume = 0.2;
					document.querySelector('#status').innerHTML = "Now playing: " + path;
				}

				function update() { 
					// this schedules a call to the update() method in 1/60 seconds
					requestAnimationFrame(update);

					//If NUM_SAMPLES (fftSize) is 256, then the first bin is 0 Hz, the second is 172 Hz, the third is 344Hz.
					// create a new array of 8-bit integers (0-255)
					let timeData = new Uint8Array(NUM_SAMPLES/2);
					let freqData = new Uint8Array(analyserNode.frequencyBinCount); 

					// populate the array with the frequency data
					// notice these arrays can be passed "by reference" 
					analyserNode.getByteTimeDomainData(timeData);
					analyserNode.getByteFrequencyData(freqData);

					// DRAW!
					ctx.clearRect(0,0,canvas.width,canvas.height);

					//Draw video
					//Zoom destination based on percentage of bass
					//(image, source x, source y, source width, source height, dest. x, dest. y, dest width, dest height)
					ctx.drawImage(videoElement,
								  0, 0,
								  videoElement.videoWidth, videoElement.videoHeight,
								  0 - (300 * bassPercent), 0 - (200 * bassPercent),
								  canvas.width + (600 * bassPercent), canvas.height + (300 * bassPercent)
								 );

					console.log(bassPercent); //Why is this so high??

					//Bar vars
					ctx.lineWidth = 5;
					let pixelsPerSection = canvas.width/freqData.length;
					let maxHeight = canvas.height;
					let minHeight = 0;
					let lastX = 0;
					let lastY = canvas.height;

					//Playback vars
					let bassSum = 0;
					let playBins = 2;

					ctx.moveTo(0,0);
					
					// loop through the data and draw!
					for(let i = 0; i < freqData.length; i++) 
					{
						if(i < playBins)
						{
							bassSum += freqData[i];
						}
						let percent = freqData[i]/255;
						let currHeight = maxHeight * percent;

						ctx.strokeStyle = 'rgb(' + currHeight + ',255,0)';

						ctx.beginPath();
						ctx.moveTo(lastX, lastY);
						ctx.lineTo(lastX, canvas.height - currHeight);
						ctx.stroke();

						lastX = lastX + pixelsPerSection;
						lastY = canvas.height - currHeight * 1.2;
						
						

					}
					manipulatePixels();

					bassPercent = (bassSum/playBins)/255;
					videoElement.playbackRate = Math.round(1.5 * bassPercent); //Round to remove error with playbackRate range

				}

				function manipulatePixels()
				{
					//Get all of the rgba pixel data of the canvas by grabbing the
					//ImageDataObject
					let imageData = ctx.getImageData(0,0,canvas.width, canvas.height);

					//imageData.data is an 8-bit typed array - values range from 0-255
					//imageData.data contains 4 values per pixel: 4 x canvas.width x canvas.height = 1024000 values!
					let data = imageData.data;
					let length = data.length;
					let width = imageData.width;

					//Iterate through each pixel. Step by 4 to use 1 pixel per iteration
					//data[i] = red, data[i+1] = green, data[i+2] = blue, data[i+3] = alpha

					for(let i = 0; i < length; i += 4)
					{
						if(controls.invert)
						{
							let red = data[i], green = data[i+1], blue = data[i+2];
							data[i] = 255 - red;
							data[i+1] = 255 - green;
							data[i+2] = 255 - blue;
						}
					}

					//Put modified data back on the canvas
					ctx.putImageData(imageData, 0 , 0);
				}

				// HELPER
				function makeColor(red, green, blue, alpha){
					var color='rgba('+red+','+green+','+blue+', '+alpha+')';
					return color;
				}

				// FULL SCREEN MODE
				function requestFullscreen(element) {
					if (element.requestFullscreen) {
						element.requestFullscreen();
					} else if (element.mozRequestFullscreen) {
						element.mozRequestFullscreen();
					} else if (element.mozRequestFullScreen) { // camel-cased 'S' was changed to 's' in spec
						element.mozRequestFullScreen();
					} else if (element.webkitRequestFullscreen) {
						element.webkitRequestFullscreen();
					}
					// .. and do nothing if the method is not supported
				};


				window.addEventListener("load",init);
			}());

		</script>
	</head>
	<body>
		<canvas id="canvas" width="1200" height="800"></canvas>
		<div id="trackControls">
			<label>Track: 
				<select id="trackSelect" >
					<option value="media/audio/New Adventure Theme.mp3">New Adventure Theme</option>
					<option value="media/audio/Peanuts Theme.mp3">Peanuts Theme</option>
					<option value="media/audio/The Picard Song.mp3">The Picard Song</option>
					<option value="media/audio/FLEXLIKEOUU.mp3">LIKEOUU</option>
				</select>
			</label>
			<audio controls loop></audio>
			<button id="fsButton">Go Full Screen</button><br>
		</div>

		<div id="audioEffects">
		</div>

		<p id="status">No Track Playing</p>

		<!-- This video element is hidden and instead drawn in canvas -->
		<video autoplay loop id="vid">
			<source id='vidsource' src="media/ninja.mp4" type="video/mp4">
		</video>

	</body>
</html>
