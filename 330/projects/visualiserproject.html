<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<title>Will & Sanketh Visualizer</title>
		<style>
			body 
			{
				background: #eeeeee;
				font-family: tahoma, verdana, sans serif;
			}

			canvas 
			{
				display: block;
				margin-left: auto;
				margin-right: auto;
				box-shadow: 4px 4px 8px rgba(0,0,0,0.5);
				background: black;
			}

			#trackControls, #audioEffects
			{
				margin-left: auto;
				margin-right: auto;
				margin-top: 2em;
				text-align: center;
			}

			#trackControls > *
			{
				margin-right: 1em;
			}

			#vid
			{
				visibility: hidden;
			}

			p
			{
				text-align: center;
			}
		</style>
		<script type="text/javascript" src="dat.gui.js"></script>
		<script>
			// An IIFE ("Iffy")
			(function(){
				"use strict";

				let NUM_SAMPLES = 256;
				let audioCtx, analyserNode, convolverNode, sourceNode;
				let canvas, ctx;
				let audioElement;
				let videoElement;
				let defaultSong = 'media/audio/New Adventure Theme.mp3';
				let invert = false;
				let reverb = false;

				let controlFunc = function()
				{
					this.invert = false;
				}
				let controls = new controlFunc();

				function init(){

					let gui = new dat.GUI();
					gui.add(controls, 'invert');

					// set up canvas stuff
					canvas = document.querySelector('canvas');
					ctx = canvas.getContext("2d");
					videoElement = document.getElementById('vid');

					// get reference to <audio> element on page
					audioElement = document.querySelector('audio');

					// call our helper function and get an analyser node
					analyserNode = createWebAudioContextAndNodes(audioElement);

					// get sound track <select> and Full Screen button working
					setupUI();

					// load and play default sound into audio element
					playStream(audioElement,defaultSong);

					// start animation loop
					update();
				}


				function createWebAudioContextAndNodes(audioElement) {
					// create new AudioContext
					// The || is because WebAudio has not been standardized across browsers yet
					// http://webaudio.github.io/web-audio-api/#the-audiocontext-interface
					audioCtx = new (window.AudioContext || window.webkitAudioContext);

					// create an analyser node
					analyserNode = audioCtx.createAnalyser();

					//create convolver node
					convolverNode = audioCtx.createConvolver();

					/*
					We will request NUM_SAMPLES number of samples or "bins" spaced equally 
					across the sound spectrum.

					If NUM_SAMPLES (fftSize) is 256, then the first bin is 0 Hz, the second is 172 Hz, 
					the third is 344Hz. Each bin contains a number between 0-255 representing 
					the amplitude of that frequency.
					*/ 

					// fft stands for Fast Fourier Transform
					analyserNode.fftSize = NUM_SAMPLES;


					// grab audio track via XHR for convolver node

					let soundSource;

					let ajaxRequest = new XMLHttpRequest();
					ajaxRequest.open('GET', 'media/impulse.ogg', true);
					ajaxRequest.responseType = 'arraybuffer';

					ajaxRequest.onload = function() {
						let audioData = ajaxRequest.response;
						audioCtx.decodeAudioData(audioData, function(buffer) {
							convolverNode.buffer = buffer;
						}, function(e){"Error with decoding audio data" + e.err});
					}

					ajaxRequest.send();

					// this is where we hook up the <audio> element to the analyserNode
					sourceNode = audioCtx.createMediaElementSource(audioElement); 
					sourceNode.connect(analyserNode);

					// here we connect to the destination i.e. speakers
					analyserNode.connect(audioCtx.destination);
					return analyserNode;
				}

				function setupUI(){
					document.querySelector("#trackSelect").onchange = function(e){
						playStream(audioElement,e.target.value);
					};

					document.querySelector("#fsButton").onclick = function(){
						requestFullscreen(canvas);
					};

					document.querySelector("#reverbBox").onchange = function(e){
						reverb = e.target.checked;
						
						if(reverb)
						{
							sourceNode.connect(convolverNode);
							convolverNode.connect(analyserNode);
							analyserNode.connect(audioCtx.destination);
						}
						else
						{
							convolverNode.disconnect();			
						}
					};
				}

				function playStream(audioElement,path){
					audioElement.src = path;
					audioElement.play();
					audioElement.volume = 0.2;
					document.querySelector('#status').innerHTML = "Now playing: " + path;
				}

				function update() { 
					// this schedules a call to the update() method in 1/60 seconds
					requestAnimationFrame(update);


					/*
				Nyquist Theorem
				http://whatis.techtarget.com/definition/Nyquist-Theorem
				The array of data we get back is 1/2 the size of the sample rate 
					*/

					// create a new array of 8-bit integers (0-255)
					var data = new Uint8Array(NUM_SAMPLES/2); 

					// populate the array with the frequency data
					// notice these arrays can be passed "by reference" 
					analyserNode.getByteFrequencyData(data);

					// DRAW!
					ctx.clearRect(0,0,canvas.width,canvas.height);

					//Draw video
					ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

					ctx.lineWidth = 5;
					let pixelsPerSection = canvas.width/data.length;
					let maxHeight = canvas.height;
					let minHeight = 0;
					let lastX = 0;
					let lastY = canvas.height;

					ctx.moveTo(0,0);

					// loop through the data and draw!
					for(var i=0; i<data.length; i++) 
					{
						let percent = data[i]/255;
						let currHeight = maxHeight * percent;

						ctx.strokeStyle = 'rgb(' + currHeight + ',255,0)';
						//ctx.strokeStyle = 'green';

						ctx.beginPath();
						ctx.moveTo(lastX, lastY);
						ctx.lineTo(lastX, 600 - currHeight);
						ctx.stroke();

						lastX = lastX + pixelsPerSection;
						lastY = 600 - currHeight * 1.2;

					}
					manipulatePixels();

				}

				function manipulatePixels()
				{
					//Get all of the rgba pixel data of the canvas by grabbing the
					//ImageDataObject
					let imageData = ctx.getImageData(0,0,canvas.width, canvas.height);

					//imageData.data is an 8-bit typed array - values range from 0-255
					//imageData.data contains 4 values per pixel: 4 x canvas.width x canvas.height = 1024000 values!
					let data = imageData.data;
					let length = data.length;
					let width = imageData.width;

					//Iterate through each pixel. Step by 4 to use 1 pixel per iteration
					//data[i] = red, data[i+1] = green, data[i+2] = blue, data[i+3] = alpha

					for(let i = 0; i < length; i += 4)
					{
						if(controls.invert)
						{
							let red = data[i], green = data[i+1], blue = data[i+2];
							data[i] = 255 - red;
							data[i+1] = 255 - green;
							data[i+2] = 255 - blue;
						}
					}

					//Put modified data back on the canvas
					ctx.putImageData(imageData, 0 , 0);
				}

				// HELPER
				function makeColor(red, green, blue, alpha){
					var color='rgba('+red+','+green+','+blue+', '+alpha+')';
					return color;
				}

				// FULL SCREEN MODE
				function requestFullscreen(element) {
					if (element.requestFullscreen) {
						element.requestFullscreen();
					} else if (element.mozRequestFullscreen) {
						element.mozRequestFullscreen();
					} else if (element.mozRequestFullScreen) { // camel-cased 'S' was changed to 's' in spec
						element.mozRequestFullScreen();
					} else if (element.webkitRequestFullscreen) {
						element.webkitRequestFullscreen();
					}
					// .. and do nothing if the method is not supported
				};


				window.addEventListener("load",init);
			}());

		</script>
	</head>
	<body>
		<canvas id="canvas" width="1200" height="800"></canvas>
		<div id="trackControls">
			<label>Track: 
				<select id="trackSelect" >
					<option value="media/audio/New Adventure Theme.mp3">New Adventure Theme</option>
					<option value="media/audio/Peanuts Theme.mp3">Peanuts Theme</option>
					<option value="media/audio/The Picard Song.mp3">The Picard Song</option>
					<option value="media/audio/slamurhead.mp3">slamurhead</option>
				</select>
			</label>
			<audio controls loop></audio>
			<button id="fsButton">Go Full Screen</button><br>
		</div>

		<div id="audioEffects">
			<div>
				<span>
					<label for="reverbBox">Reverb</label>
					<input type='checkbox' id='reverbBox'>
				</span>
			</div>
		</div>

		<p id="status">No Track Playing</p>


		<video autoplay loop id="vid">
			<source src="media/ninja.mp4" type="video/mp4">
		</video>

	</body>
</html>
